{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdJVkGpzx2ku",
        "outputId": "c770cdff-0b4f-4e8f-b7f9-72e979446588"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm librosa moviepy torch pytorch_pretrained_biggan "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrjCzBhbhnqb",
        "outputId": "7806cd6d-392e-40f5-ad19-4542cb7d217f"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import argparse\n",
        "import numpy as np\n",
        "import moviepy.editor as mpy\n",
        "import random\n",
        "import torch\n",
        "import PIL.Image as Image\n",
        "from tqdm import tqdm\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
        "                                       save_as_images, display_in_terminal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLTrb-eVzFGu",
        "outputId": "8f69c967-4e00-4c8b-8d44-fb3ab88ef40a"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--song\",required=True)\n",
        "parser.add_argument(\"--resolution\", default='512')\n",
        "parser.add_argument(\"--duration\", type=int)\n",
        "parser.add_argument(\"--pitch_sensitivity\", type=int, default=220)\n",
        "parser.add_argument(\"--tempo_sensitivity\", type=float, default=0.25)\n",
        "parser.add_argument(\"--depth\", type=float, default=1)\n",
        "parser.add_argument(\"--classes\", nargs='+', type=int)\n",
        "parser.add_argument(\"--num_classes\", type=int, default=12)\n",
        "parser.add_argument(\"--sort_classes_by_power\", type=int, default=0)\n",
        "parser.add_argument(\"--jitter\", type=float, default=0.5)\n",
        "parser.add_argument(\"--frame_length\", type=int, default=512)\n",
        "parser.add_argument(\"--truncation\", type=float, default=1)\n",
        "parser.add_argument(\"--smooth_factor\", type=int, default=20)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=30)\n",
        "parser.add_argument(\"--use_previous_classes\", type=int, default=0)\n",
        "parser.add_argument(\"--use_previous_vectors\", type=int, default=0)\n",
        "parser.add_argument(\"--output_file\", default=\"output.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ_T_ptuzadJ"
      },
      "outputs": [],
      "source": [
        "args = parser.parse_args(args=['--song', 'beethoven.mp3',\n",
        "                               '--resolution', '128',\n",
        "                               '--pitch_sensitivity', '280',\n",
        "                               '--tempo_sensitivity', '0.1',\n",
        "                               '--depth', '0.5',\n",
        "                               '--truncation', '0.4',\n",
        "                               '--smooth_factor', '30',\n",
        "                               '--num_classes', '7',\n",
        "                               '--classes', '14', '84', '134', '144', '100', '23', '22',\n",
        "                               '--batch_size', '20',\n",
        "                               '--duration', '20',\n",
        "                               ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBJBQdE47pU",
        "outputId": "00c7f826-e47c-4183-c8ad-4975262b1f2d"
      },
      "outputs": [],
      "source": [
        "#read song\n",
        "if args.song:\n",
        "    song=args.song\n",
        "    print('\\nReading audio \\n')\n",
        "    y, sr = librosa.load(song)\n",
        "else:\n",
        "    raise ValueError(\"you must enter an audio file name in the --song argument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8668SPH5IMJ"
      },
      "outputs": [],
      "source": [
        "#set model name based on resolution\n",
        "model_name='biggan-deep-' + args.resolution\n",
        "\n",
        "frame_length=args.frame_length\n",
        "\n",
        "#set pitch sensitivity\n",
        "pitch_sensitivity=(300-args.pitch_sensitivity) * 512 / frame_length\n",
        "\n",
        "#set tempo sensitivity\n",
        "tempo_sensitivity=args.tempo_sensitivity * frame_length / 512\n",
        "\n",
        "#set depth\n",
        "depth=args.depth\n",
        "\n",
        "#set number of classes  \n",
        "num_classes=args.num_classes\n",
        "\n",
        "#set sort_classes_by_power    \n",
        "sort_classes_by_power=args.sort_classes_by_power\n",
        "\n",
        "#set jitter\n",
        "jitter=args.jitter\n",
        "    \n",
        "#set truncation\n",
        "truncation=args.truncation\n",
        "\n",
        "#set batch size  \n",
        "batch_size=args.batch_size\n",
        "\n",
        "#set use_previous_classes\n",
        "use_previous_vectors=args.use_previous_vectors\n",
        "\n",
        "#set use_previous_vectors\n",
        "use_previous_classes=args.use_previous_classes\n",
        "    \n",
        "#set output name\n",
        "outname=args.output_file\n",
        "\n",
        "#set smooth factor\n",
        "if args.smooth_factor > 1:\n",
        "    smooth_factor=int(args.smooth_factor * 512 / frame_length)\n",
        "else:\n",
        "    smooth_factor=args.smooth_factor\n",
        "\n",
        "#set duration  \n",
        "if args.duration:\n",
        "    seconds=args.duration\n",
        "    frame_lim=int(np.floor(seconds*22050/frame_length/batch_size))\n",
        "else:\n",
        "    frame_lim=int(np.floor(len(y)/sr*22050/frame_length/batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjrw0DfH5Qw_",
        "outputId": "c7ce792c-1bcd-4e37-97fc-b37ac5a21c38"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model\n",
        "model = BigGAN.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5iOs3FQ5cNa",
        "outputId": "8979386a-cb3a-421d-da10-f74c54336a6d"
      },
      "outputs": [],
      "source": [
        "#set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1jNsX9d6KHj"
      },
      "outputs": [],
      "source": [
        "#create spectrogram\n",
        "spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000, hop_length=frame_length)\n",
        "\n",
        "#get mean power at each time point\n",
        "specm=np.mean(spec,axis=0)\n",
        "\n",
        "#compute power gradient across time points\n",
        "gradm=np.gradient(specm)\n",
        "\n",
        "#set max to 1\n",
        "gradm=gradm/np.max(gradm)\n",
        "\n",
        "#set negative gradient time points to zero \n",
        "gradm = gradm.clip(min=0)\n",
        "    \n",
        "#normalize mean power between 0-1\n",
        "specm=(specm-np.min(specm))/np.ptp(specm)\n",
        "\n",
        "#create chromagram of pitches X time points\n",
        "chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=frame_length)\n",
        "\n",
        "#sort pitches by overall power \n",
        "chromasort=np.argsort(np.mean(chroma,axis=1))[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmE6GcX46PjG"
      },
      "outputs": [],
      "source": [
        "if args.classes:\n",
        "    classes=args.classes\n",
        "    if len(classes) not in [12,num_classes]:\n",
        "        raise ValueError(\"The number of classes entered in the --class argument must equal 12 or [num_classes] if specified\")\n",
        "    \n",
        "elif args.use_previous_classes==1:\n",
        "    cvs=np.load('class_vectors.npy')\n",
        "    classes=list(np.where(cvs[0]>0)[0])\n",
        "    \n",
        "else: #select 12 random classes\n",
        "    cls1000=list(range(1000))\n",
        "    random.shuffle(cls1000)\n",
        "    classes=cls1000[:12]\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "if sort_classes_by_power==1:\n",
        "\n",
        "    classes=[classes[s] for s in np.argsort(chromasort[:num_classes])]\n",
        "\n",
        "\n",
        "\n",
        "#initialize first class vector\n",
        "cv1=np.zeros(1000)\n",
        "for pi,p in enumerate(chromasort[:num_classes]):\n",
        "    \n",
        "    if num_classes < 12:\n",
        "        cv1[classes[pi]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]       \n",
        "    else:\n",
        "        cv1[classes[p]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]\n",
        "\n",
        "#initialize first noise vector\n",
        "nv1 = truncated_noise_sample(truncation=truncation)[0]\n",
        "\n",
        "#initialize list of class and noise vectors\n",
        "class_vectors=[cv1]\n",
        "noise_vectors=[nv1]\n",
        "\n",
        "#initialize previous vectors (will be used to track the previous frame)\n",
        "cvlast=cv1\n",
        "nvlast=nv1\n",
        "\n",
        "\n",
        "#initialize the direction of noise vector unit updates\n",
        "update_dir=np.zeros(128)\n",
        "for ni,n in enumerate(nv1):\n",
        "    if n<0:\n",
        "        update_dir[ni] = 1\n",
        "    else:\n",
        "        update_dir[ni] = -1\n",
        "\n",
        "\n",
        "#initialize noise unit update\n",
        "update_last=np.zeros(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkGDCSFb6WV3",
        "outputId": "93e91fe7-cbe0-43e2-ef7c-1fa8d09a3d03"
      },
      "outputs": [],
      "source": [
        "#get new jitters\n",
        "def new_jitters(jitter):\n",
        "    jitters=np.zeros(128)\n",
        "    for j in range(128):\n",
        "        if random.uniform(0,1)<0.5:\n",
        "            jitters[j]=1\n",
        "        else:\n",
        "            jitters[j]=1-jitter        \n",
        "    return jitters\n",
        "\n",
        "\n",
        "#get new update directions\n",
        "def new_update_dir(nv2,update_dir):\n",
        "    for ni,n in enumerate(nv2):                  \n",
        "        if n >= 2*truncation - tempo_sensitivity:\n",
        "            update_dir[ni] = -1  \n",
        "                        \n",
        "        elif n < -2*truncation + tempo_sensitivity:\n",
        "            update_dir[ni] = 1   \n",
        "    return update_dir\n",
        "\n",
        "\n",
        "#smooth class vectors\n",
        "def smooth(class_vectors,smooth_factor):\n",
        "    \n",
        "    if smooth_factor==1:\n",
        "        return class_vectors\n",
        "    \n",
        "    class_vectors_terp=[]\n",
        "    for c in range(int(np.floor(len(class_vectors)/smooth_factor)-1)):  \n",
        "        ci=c*smooth_factor          \n",
        "        cva=np.mean(class_vectors[int(ci):int(ci)+smooth_factor],axis=0)\n",
        "        cvb=np.mean(class_vectors[int(ci)+smooth_factor:int(ci)+smooth_factor*2],axis=0)\n",
        "                    \n",
        "        for j in range(smooth_factor):                                 \n",
        "            cvc = cva*(1-j/(smooth_factor-1)) + cvb*(j/(smooth_factor-1))                                          \n",
        "            class_vectors_terp.append(cvc)\n",
        "            \n",
        "    return np.array(class_vectors_terp)\n",
        "\n",
        "\n",
        "#normalize class vector between 0-1\n",
        "def normalize_cv(cv2):\n",
        "    min_class_val = min(i for i in cv2 if i != 0)\n",
        "    for ci,c in enumerate(cv2):\n",
        "        if c==0:\n",
        "            cv2[ci]=min_class_val    \n",
        "    cv2=(cv2-min_class_val)/np.ptp(cv2) \n",
        "    \n",
        "    return cv2\n",
        "\n",
        "\n",
        "print('\\nGenerating input vectors \\n')\n",
        "\n",
        "for i in tqdm(range(len(gradm))):   \n",
        "    \n",
        "    #print progress\n",
        "    pass\n",
        "\n",
        "    #update jitter vector every 100 frames by setting ~half of noise vector units to lower sensitivity\n",
        "    if i%200==0:\n",
        "        jitters=new_jitters(jitter)\n",
        "\n",
        "    #get last noise vector\n",
        "    nv1=nvlast\n",
        "\n",
        "    #set noise vector update based on direction, sensitivity, jitter, and combination of overall power and gradient of power\n",
        "    update = np.array([tempo_sensitivity for k in range(128)]) * (gradm[i]+specm[i]) * update_dir * jitters \n",
        "    \n",
        "    #smooth the update with the previous update (to avoid overly sharp frame transitions)\n",
        "    update=(update+update_last*3)/4\n",
        "    \n",
        "    #set last update\n",
        "    update_last=update\n",
        "        \n",
        "    #update noise vector\n",
        "    nv2=nv1+update\n",
        "\n",
        "    #append to noise vectors\n",
        "    noise_vectors.append(nv2)\n",
        "    \n",
        "    #set last noise vector\n",
        "    nvlast=nv2\n",
        "                   \n",
        "    #update the direction of noise units\n",
        "    update_dir=new_update_dir(nv2,update_dir)\n",
        "\n",
        "    #get last class vector\n",
        "    cv1=cvlast\n",
        "    \n",
        "    #generate new class vector\n",
        "    cv2=np.zeros(1000)\n",
        "    for j in range(num_classes):\n",
        "        \n",
        "        cv2[classes[j]] = (cvlast[classes[j]] + ((chroma[chromasort[j]][i])/(pitch_sensitivity)))/(1+(1/((pitch_sensitivity))))\n",
        "\n",
        "    #if more than 6 classes, normalize new class vector between 0 and 1, else simply set max class val to 1\n",
        "    if num_classes > 6:\n",
        "        cv2=normalize_cv(cv2)\n",
        "    else:\n",
        "        cv2=cv2/np.max(cv2)\n",
        "    \n",
        "    #adjust depth    \n",
        "    cv2=cv2*depth\n",
        "    \n",
        "    #this prevents rare bugs where all classes are the same value\n",
        "    if np.std(cv2[np.where(cv2!=0)]) < 0.0000001:\n",
        "        cv2[classes[0]]=cv2[classes[0]]+0.01\n",
        "\n",
        "    #append new class vector\n",
        "    class_vectors.append(cv2)\n",
        "    \n",
        "    #set last class vector\n",
        "    cvlast=cv2\n",
        "\n",
        "\n",
        "#interpolate between class vectors of bin size [smooth_factor] to smooth frames \n",
        "class_vectors=smooth(class_vectors,smooth_factor)\n",
        "\n",
        "\n",
        "#check whether to use vectors from last run\n",
        "if use_previous_vectors==1:   \n",
        "    #load vectors from previous run\n",
        "    class_vectors=np.load('class_vectors.npy')\n",
        "    noise_vectors=np.load('noise_vectors.npy')\n",
        "else:\n",
        "    #save record of vectors for current video\n",
        "    np.save('class_vectors.npy',class_vectors)\n",
        "    np.save('noise_vectors.npy',noise_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJsRuCYC6d4A",
        "outputId": "7d15af33-8ee4-45d8-f065-415ae9ce0281"
      },
      "outputs": [],
      "source": [
        "#convert to Tensor\n",
        "noise_vectors = torch.Tensor(np.array(noise_vectors))      \n",
        "class_vectors = torch.Tensor(np.array(class_vectors))      \n",
        "\n",
        "\n",
        "#Generate frames in batches of batch_size\n",
        "\n",
        "print('\\n\\nGenerating frames \\n')\n",
        "\n",
        "#send to CUDA if running on GPU\n",
        "model=model.to(device)\n",
        "noise_vectors=noise_vectors.to(device)\n",
        "class_vectors=class_vectors.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59lonv5G6kC7"
      },
      "outputs": [],
      "source": [
        "########################################\n",
        "## Extract bytescale, toimage from Scipy 1.1.0\n",
        "#  which is is deprecated, and removed in Scipy 1.2.0\n",
        "# from https://github.com/scipy/scipy/blob/368dbad596a0bd0d5a88a7aec381fdc912440ee1/scipy/misc/pilutil.py#L286-L409\n",
        "def bytescale(data, cmin=None, cmax=None, high=255, low=0):\n",
        "    \"\"\"\n",
        "    Byte scales an array (image).\n",
        "    Byte scaling means converting the input image to uint8 dtype and scaling\n",
        "    the range to ``(low, high)`` (default 0-255).\n",
        "    If the input image already has dtype uint8, no scaling is done.\n",
        "    This function is only available if Python Imaging Library (PIL) is installed.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : ndarray\n",
        "        PIL image data array.\n",
        "    cmin : scalar, optional\n",
        "        Bias scaling of small values. Default is ``data.min()``.\n",
        "    cmax : scalar, optional\n",
        "        Bias scaling of large values. Default is ``data.max()``.\n",
        "    high : scalar, optional\n",
        "        Scale max value to `high`.  Default is 255.\n",
        "    low : scalar, optional\n",
        "        Scale min value to `low`.  Default is 0.\n",
        "    Returns\n",
        "    -------\n",
        "    img_array : uint8 ndarray\n",
        "        The byte-scaled array.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from scipy.misc import bytescale\n",
        "    >>> img = np.array([[ 91.06794177,   3.39058326,  84.4221549 ],\n",
        "    ...                 [ 73.88003259,  80.91433048,   4.88878881],\n",
        "    ...                 [ 51.53875334,  34.45808177,  27.5873488 ]])\n",
        "    >>> bytescale(img)\n",
        "    array([[255,   0, 236],\n",
        "           [205, 225,   4],\n",
        "           [140,  90,  70]], dtype=uint8)\n",
        "    >>> bytescale(img, high=200, low=100)\n",
        "    array([[200, 100, 192],\n",
        "           [180, 188, 102],\n",
        "           [155, 135, 128]], dtype=uint8)\n",
        "    >>> bytescale(img, cmin=0, cmax=255)\n",
        "    array([[91,  3, 84],\n",
        "           [74, 81,  5],\n",
        "           [52, 34, 28]], dtype=uint8)\n",
        "    \"\"\"\n",
        "    if data.dtype == np.uint8:\n",
        "        return data\n",
        "\n",
        "    if high > 255:\n",
        "        raise ValueError(\"`high` should be less than or equal to 255.\")\n",
        "    if low < 0:\n",
        "        raise ValueError(\"`low` should be greater than or equal to 0.\")\n",
        "    if high < low:\n",
        "        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n",
        "\n",
        "    if cmin is None:\n",
        "        cmin = data.min()\n",
        "    if cmax is None:\n",
        "        cmax = data.max()\n",
        "\n",
        "    cscale = cmax - cmin\n",
        "    if cscale < 0:\n",
        "        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n",
        "    elif cscale == 0:\n",
        "        cscale = 1\n",
        "\n",
        "    scale = float(high - low) / cscale\n",
        "    bytedata = (data - cmin) * scale + low\n",
        "    return (bytedata.clip(low, high) + 0.5).astype(np.uint8)\n",
        "\n",
        "def toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None,\n",
        "            mode=None, channel_axis=None):\n",
        "    \"\"\"Takes a numpy array and returns a PIL image.\n",
        "    This function is only available if Python Imaging Library (PIL) is installed.\n",
        "    The mode of the PIL image depends on the array shape and the `pal` and\n",
        "    `mode` keywords.\n",
        "    For 2-D arrays, if `pal` is a valid (N,3) byte-array giving the RGB values\n",
        "    (from 0 to 255) then ``mode='P'``, otherwise ``mode='L'``, unless mode\n",
        "    is given as 'F' or 'I' in which case a float and/or integer array is made.\n",
        "    .. warning::\n",
        "        This function uses `bytescale` under the hood to rescale images to use\n",
        "        the full (0, 255) range if ``mode`` is one of ``None, 'L', 'P', 'l'``.\n",
        "        It will also cast data for 2-D images to ``uint32`` for ``mode=None``\n",
        "        (which is the default).\n",
        "    Notes\n",
        "    -----\n",
        "    For 3-D arrays, the `channel_axis` argument tells which dimension of the\n",
        "    array holds the channel data.\n",
        "    For 3-D arrays if one of the dimensions is 3, the mode is 'RGB'\n",
        "    by default or 'YCbCr' if selected.\n",
        "    The numpy array must be either 2 dimensional or 3 dimensional.\n",
        "    \"\"\"\n",
        "    data = np.asarray(arr)\n",
        "    if np.iscomplexobj(data):\n",
        "        raise ValueError(\"Cannot convert a complex-valued array.\")\n",
        "    shape = list(data.shape)\n",
        "    valid = len(shape) == 2 or ((len(shape) == 3) and\n",
        "                                ((3 in shape) or (4 in shape)))\n",
        "    if not valid:\n",
        "        raise ValueError(\"'arr' does not have a suitable array shape for \"\n",
        "                         \"any mode.\")\n",
        "    if len(shape) == 2:\n",
        "        shape = (shape[1], shape[0])  # columns show up first\n",
        "        if mode == 'F':\n",
        "            data32 = data.astype(np.float32)\n",
        "            image = Image.frombytes(mode, shape, data32.tobytes())\n",
        "            return image\n",
        "        if mode in [None, 'L', 'P']:\n",
        "            bytedata = bytescale(data, high=high, low=low,\n",
        "                                 cmin=cmin, cmax=cmax)\n",
        "            image = Image.frombytes('L', shape, bytedata.tobytes())\n",
        "            if pal is not None:\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tobytes())\n",
        "                # Becomes a mode='P' automagically.\n",
        "            elif mode == 'P':  # default gray-scale\n",
        "                pal = (arange(0, 256, 1, dtype=np.uint8)[:, newaxis] *\n",
        "                       ones((3,), dtype=np.uint8)[newaxis, :])\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tobytes())\n",
        "            return image\n",
        "        if mode == '1':  # high input gives threshold for 1\n",
        "            bytedata = (data > high)\n",
        "            image = Image.frombytes('1', shape, bytedata.tobytes())\n",
        "            return image\n",
        "        if cmin is None:\n",
        "            cmin = amin(ravel(data))\n",
        "        if cmax is None:\n",
        "            cmax = amax(ravel(data))\n",
        "        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n",
        "        if mode == 'I':\n",
        "            data32 = data.astype(np.uint32)\n",
        "            image = Image.frombytes(mode, shape, data32.tobytes())\n",
        "        else:\n",
        "            raise ValueError(_errstr)\n",
        "        return image\n",
        "\n",
        "    # if here then 3-d array with a 3 or a 4 in the shape length.\n",
        "    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n",
        "    if channel_axis is None:\n",
        "        if (3 in shape):\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 3)[0]\n",
        "        else:\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 4)\n",
        "            if len(ca):\n",
        "                ca = ca[0]\n",
        "            else:\n",
        "                raise ValueError(\"Could not find channel dimension.\")\n",
        "    else:\n",
        "        ca = channel_axis\n",
        "\n",
        "    numch = shape[ca]\n",
        "    if numch not in [3, 4]:\n",
        "        raise ValueError(\"Channel axis dimension is not valid.\")\n",
        "\n",
        "    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n",
        "    if ca == 2:\n",
        "        strdata = bytedata.tobytes()\n",
        "        shape = (shape[1], shape[0])\n",
        "    elif ca == 1:\n",
        "        strdata = np.transpose(bytedata, (0, 2, 1)).tobytes()\n",
        "        shape = (shape[2], shape[0])\n",
        "    elif ca == 0:\n",
        "        strdata = np.transpose(bytedata, (1, 2, 0)).tobytes()\n",
        "        shape = (shape[2], shape[1])\n",
        "    if mode is None:\n",
        "        if numch == 3:\n",
        "            mode = 'RGB'\n",
        "        else:\n",
        "            mode = 'RGBA'\n",
        "\n",
        "    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n",
        "        raise ValueError(_errstr)\n",
        "\n",
        "    if mode in ['RGB', 'YCbCr']:\n",
        "        if numch != 3:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "    if mode in ['RGBA', 'CMYK']:\n",
        "        if numch != 4:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "\n",
        "    # Here we know data and mode is correct\n",
        "    image = Image.frombytes(mode, shape, strdata)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15yRTGGr6ncZ",
        "outputId": "528041c9-0f33-4e7a-a545-26f4983d8606"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "\n",
        "for i in tqdm(range(frame_lim)):\n",
        "    \n",
        "    #print progress\n",
        "    pass\n",
        "\n",
        "    if (i+1)*batch_size > len(class_vectors):\n",
        "        torch.cuda.empty_cache()\n",
        "        break\n",
        "    \n",
        "    #get batch\n",
        "    noise_vector=noise_vectors[i*batch_size:(i+1)*batch_size]\n",
        "    class_vector=class_vectors[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "    # Generate images\n",
        "    with torch.no_grad():\n",
        "        output = model(noise_vector, class_vector, truncation)\n",
        "\n",
        "    output_cpu=output.cpu().data.numpy()\n",
        "\n",
        "    #convert to image array and add to frames\n",
        "    for out in output_cpu:    \n",
        "        im=np.array(toimage(out))\n",
        "        frames.append(im)\n",
        "        \n",
        "    #empty cuda cache\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpC5vyKZ6qF3",
        "outputId": "435b4625-2e17-465e-d1e0-5a5baafdef0c"
      },
      "outputs": [],
      "source": [
        "#Save video  \n",
        "aud = mpy.AudioFileClip(song, fps = 44100) \n",
        "\n",
        "if args.duration:\n",
        "    aud.duration=args.duration\n",
        "\n",
        "clip = mpy.ImageSequenceClip(frames, fps=22050/frame_length)\n",
        "clip = clip.set_audio(aud)\n",
        "clip.write_videofile(outname,audio_codec='aac')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "deep-music-visualizer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a224b72f35db62ccadfbdde74117a416d71e38ec4abefa147fd22031fca0256b"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('deep-music-visualizer')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
